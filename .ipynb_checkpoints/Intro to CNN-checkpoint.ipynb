{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to convolutional neural networks?\n",
    "\n",
    "### 1.1 Why?\n",
    "\n",
    "#### 1.1.1 CNNs can deal better with large images (until now, images used were fairly small)\n",
    "\n",
    "- Imagine an color image with 500 x 500 pixels, this means you would    end up having 500 x 500 x 3 = 750,000 input features, $(x_1,...,x_{750,000})$.\n",
    "- next, imagine having 2000 hidden units in the first hidden layer. Then the matrix $w^{[1]}$ would have dimensions (2000 x 750,000), and will have 1.5 billion parameters. So it becomes a very high-dimensional problem!\n",
    "\n",
    "#### 1.1.1 CNNs have certain features that identify patterns in images because of  \"convolution operation\"\n",
    "\n",
    "- Dense layers learn global patterns in their input feature space\n",
    "\n",
    "- Convolution layers learn local patterns, and this leads to the following interesting features:\n",
    "    - Unlike with densely connected networks, when a convolutional neural network recognizes a patterns let's say, in the upper-right corner of a picture, it can recognize it anywhere else in a picture. \n",
    "    - Deeper convolutional neural networks can learn spatial hierarchies. A first layer will learn small local patterns, a second layer will learn larger patterns using features of the first layer patterns, etc. \n",
    "     \n",
    "\n",
    "### 1.2 What are they used for?\n",
    "- Image classification\n",
    "- Object detection in images\n",
    "- Picture neural style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The convolution operation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The basic convolution operation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea: detect edges in your image. Typically, we'll detect vertical or horizontal edges. Let's look at what horizontal edge detection would look like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simplified 5 x 5 pixel image (greyscale!). You use a so-called \"filter\" (denoted on the right) to perform a convolution operation. This particular filter operation will detect horizontal edges. The matrix in the left should have number in it (from 1-255, or let's assume we rescaled it to number 1-10). The output is a 3 x 3 matrix. (*This example is for computational clarity, no clear edges*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What dimension would the output matrix have had if we had started from a 7 x 7 matrix? And a 64 x 64 matrix?\n",
    "\n",
    "(*Then, create a new example with a clear edge and look at the output*)\n",
    "\n",
    "In Keras, function for the convolution step is `Conv2D`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downsides of using filters in images:\n",
    "- image shrinks with each convolution layer and you're throwing away information in each layer!\n",
    "    - Starting from a 5 x 5 matrix, and using a 3 x 3 matrix, you end up with a 3 x 3 image. \n",
    "    - Starting from a 10 x 10 matrix, and using a 3 x 3 matrix, you end up with a 8 x 8 image. \n",
    "    - etc.\n",
    "- pixels around the edges are used much less in the outputs because of the way that filters work.\n",
    "\n",
    "Solution for both of these problems: pad your image before applying the convolution! just one layer of pixels around the edges preserved the image size!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical layers in a CNN: convolution layers, pooling layers, Fully connected layers\n",
    "- Convolution layer:\n",
    "   - Performing a basic convolution: how filters work (to find \"edges\")\n",
    "   - Introduce padding (adding edges to pictures to avoid info shrinkage)\n",
    "   - introduce striding (how filter is shifter along the image)\n",
    "   - Build your own convolution layer taking into account: padding, striding, filter size, number of filters\n",
    "- Pooling layer: makes detected features more robust, works well\n",
    "  - Preserves important features\n",
    "  - Has no parameters!\n",
    "  - Max pooling, also average pooling\n",
    "- Add fully connected layers towards the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n",
    "\n",
    "https://datascience.stackexchange.com/questions/16463/what-is-are-the-default-filters-used-by-keras-convolution2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
